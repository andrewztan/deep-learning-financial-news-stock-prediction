{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import nltk \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "from datetime import date\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "with open('word_embeddings/run_info.p', 'r') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "info2index = x['info2index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "event_embeddings = pd.read_csv(\"word_embeddings/u_epoch_500.csv\", header = None)\n",
    "embedding_lst = []\n",
    "for row in event_embeddings.iterrows():\n",
    "    index, data = row \n",
    "    temp = data.tolist()\n",
    "    actual_data = [float(x) for x in temp[0].split()]\n",
    "    embedding_lst.append(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_to_month = {\"01\": \"Jan\", \"02\":\"Feb\", \"03\":\"Mar\", \"04\":\"Apr\", \"05\":\"May\", \"06\": \"Jun\", \"07\":\"Jul\", \"08\":\"Aug\", \"09\":\"Sep\", \"10\":\"Oct\", \"11\":\"Nov\", \"12\":\"Dec\"}\n",
    "def conv_num_to_string(d): #ex: conv_num_to_string('20041001') = '01-Oct-04'\n",
    "    year = d[0:4]\n",
    "    month = d[4:6]\n",
    "    day = d[6:8]\n",
    "    new = day + \"-\" + number_to_month[month] + \"-\" + year[2:4]\n",
    "    return new \n",
    "\n",
    "def numeric_day_distance(day1, day2): #'20140111', '20150115'\n",
    "    d0 = date(int(day1[0:4]), int(day1[4:6]), int(day1[6:8]) )\n",
    "    d1 = date(int(day2[0:4]), int(day2[4:6]), int(day2[6:8]) )\n",
    "    delta = d0 - d1 \n",
    "    return abs(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stock_to_events = {}\n",
    "for key_ in info2index:\n",
    "    stock_ = key_[0]\n",
    "    embedding_to_index = info2index[key_]\n",
    "    date_ = key_[1]\n",
    "    event = key_[2]\n",
    "    new_value = [date_, embedding_to_index]\n",
    "    if stock_ in stock_to_events: \n",
    "        stock_to_events[stock_].append(new_value)\n",
    "    else:\n",
    "        stock_to_events[stock_] = [new_value]\n",
    "\n",
    "for stock_ in stock_to_events:\n",
    "    stock_to_events[stock_] = sorted( stock_to_events[stock_], key = lambda x: x[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOOGL', 'INTC', 'AAPL', 'CSCO', 'AMD', 'QCOM', 'NVDA', 'AMZN', 'MSFT', 'IBM']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_to_events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    stock_length = {}\n",
    "    stock_length[\"Number of Articles\"] = len(stock_to_events[stock])\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Number of Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IBM</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Number of Articles\n",
       "0      GOOGL                 528\n",
       "1       INTC                 409\n",
       "2       AAPL                2292\n",
       "3       CSCO                 229\n",
       "4        AMD                  23\n",
       "5       QCOM                 351\n",
       "6       NVDA                  54\n",
       "7       AMZN                1062\n",
       "8       MSFT                 830\n",
       "9        IBM                 415"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ [\"Stock Name\", \"Number of Articles\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def up_down_ratio(stock, day_lag): #ex: sentiment_to_price_plot(\"AAPL\", 1, 'neg')\n",
    "    stock_data = news_csv[news_csv[\"stock\"] == stock]\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    total = []\n",
    "    for index, row in stock_data.iterrows():\n",
    "    \n",
    "\n",
    "        day = conv_num_to_string(str(row[\"date\"]) )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            \n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            #print next_price[\"Date\"], google_price_csv.iloc[row_index][\"Date\"]\n",
    "            diff = next_price[\"Close\"] - next_price[\"Open\"]\n",
    "            if diff >= 0.0:\n",
    "                total.append(1) \n",
    "            else:\n",
    "                total.append(0)\n",
    "    return 100*sum(total)/len(total)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    if stock != 'IBM':\n",
    "        stock_length = {}\n",
    "        stock_length[\"Price Up Percentage\"] = up_down_ratio(stock, 1)\n",
    "        stock_length[\"Stock Name\"] = stock\n",
    "        stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Price Up Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Price Up Percentage\n",
       "0      GOOGL                   49\n",
       "1       INTC                   49\n",
       "2       AAPL                   48\n",
       "3       CSCO                   60\n",
       "4        AMD                   50\n",
       "5       QCOM                   45\n",
       "6       NVDA                   72\n",
       "7       AMZN                   48\n",
       "8       MSFT                   51"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\", \"Price Up Percentage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])\n",
    "google_price_csv = pd.read_csv(\"price_data/GOOGL_2006-01-01_to_2017-11-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def short_term_embedding_to_class(stock, day_lag, training_ratio, shuff_bool, epoch_size):\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for event in stock_to_events[stock]:\n",
    "        \n",
    "        \n",
    "        day = conv_num_to_string( event[0]    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp_x.append( embedding_lst[event[1]]  )\n",
    "            \n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            \n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "            \n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------\n",
    "    \n",
    "    input_size = 100\n",
    "    hidden_size = 150\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = epoch_size\n",
    "    batch_size = 100\n",
    "    \n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "    \n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "    \n",
    "    train_x = torch.FloatTensor(train_x)\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    \n",
    "    \n",
    "    test_x = torch.FloatTensor(test_x)\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    \n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=shuff_bool)\n",
    "    \n",
    "    \n",
    "    test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "    \n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size, hidden_size)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out) \n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, hidden_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader):\n",
    "            \n",
    "            inp = Variable(inp)\n",
    "            outp = Variable(outp)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            \n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "    \n",
    "    return (str(train_accuracy)[0:5], str(test_accuracy)[0:5] )\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.835', '0.551')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_term_embedding_to_class('GOOGL', 1, 0.5, False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "x_axis = range(10,510,10)\n",
    "training_acc = []\n",
    "test_acc =[]\n",
    "for e in x_axis:\n",
    "    print e\n",
    "    output = total_embedding_to_class('AAPL', 0.7, False, e)\n",
    "    first = float(output[0])\n",
    "    second = float(output[1])\n",
    "    training_acc.append(first)\n",
    "    test_acc.append(second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQkREYmlICEiIrH+P426CJefSOg6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74c8e8d1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab\n",
    "pylab.plot(x_axis,training_acc, 'r', label = 'training acc')\n",
    "pylab.plot(x_axis, test_acc, 'b', label = 'test acc')\n",
    "pylab.legend(loc = 'lower left')\n",
    "pylab.xlim(10, 500)\n",
    "pylab.ylim(0.0,1.0)\n",
    "pylab.title(\"Full Network No Shuffling on AAPL\")\n",
    "pylab.xlabel(\"Epoch Size\")\n",
    "pylab.ylabel(\"Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def total_embedding_to_class(stock, training_ratio, shuff_bool, epoch_size): \n",
    "\n",
    "\n",
    "    #----------------------------LAGS\n",
    "    day_lag = 1 \n",
    "    week_lag = 7\n",
    "    month_lag = 30\n",
    "    #--------------------------- NN parameters\n",
    "    input_size = 100\n",
    "    window_size_convM =3\n",
    "    hidden_size_convM = 20\n",
    "\n",
    "    window_size_convL =3 \n",
    "    hidden_size_convL = 40\n",
    "\n",
    "\n",
    "    hidden_size_end = 200\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = epoch_size\n",
    "    batch_size = 50\n",
    "\n",
    "    #training_ratio = 0.8\n",
    "    #stock = 'AAPL'\n",
    "\n",
    "    #----------------------------------- PARAMTETRS\n",
    "\n",
    "\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for i in range(len(stock_to_events[stock]) ):\n",
    "        event = stock_to_events[stock][i]\n",
    "\n",
    "\n",
    "        date_numeric = event[0]\n",
    "        day = conv_num_to_string( date_numeric    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp = {}\n",
    "            temp[\"day\"] = embedding_lst[event[1]]\n",
    "\n",
    "\n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "\n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "\n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "\n",
    "\n",
    "\n",
    "            temp[\"week\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= week_lag ) :\n",
    "                temp['week'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "\n",
    "            temp[\"month\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= month_lag ) :\n",
    "                temp['month'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "            temp_x.append(temp)\n",
    "    #--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "\n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "\n",
    "\n",
    "    max_event_length_week = max([len(day_embedding[\"week\"]) for day_embedding in temp_x ])\n",
    "    max_event_length_month = max([len(day_embedding[\"month\"]) for day_embedding in temp_x ])\n",
    "\n",
    "\n",
    "    train_x_concatenate = []\n",
    "\n",
    "\n",
    "\n",
    "    for day_embedding in train_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        train_x_concatenate.append(block)\n",
    "\n",
    "    train_x_concatenate = torch.FloatTensor(train_x_concatenate)\n",
    "\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    train_x_concatenate_temp = torch.utils.data.TensorDataset(train_x_concatenate, train_y)\n",
    "    train_loader_total = torch.utils.data.DataLoader(dataset=train_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=shuff_bool)\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------\n",
    "\n",
    "    test_x_concatenate = []\n",
    "\n",
    "\n",
    "    for day_embedding in test_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        test_x_concatenate.append(block)\n",
    "\n",
    "\n",
    "    test_x_concatenate = torch.FloatTensor(test_x_concatenate)\n",
    "\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    test_x_concatenate_temp = torch.utils.data.TensorDataset(test_x_concatenate, test_y)\n",
    "    test_loader_total = torch.utils.data.DataLoader(dataset=test_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size + hidden_size_convM + hidden_size_convL , hidden_size_end)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size_end, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "\n",
    "            self.convM = nn.Conv1d(max_event_length_week, hidden_size_convM, window_size_convM, padding = 1 )\n",
    "            self.poolM = nn.MaxPool1d(input_size)\n",
    "\n",
    "            self.convL = nn.Conv1d(max_event_length_month, hidden_size_convL, window_size_convL, padding = 1 )\n",
    "            self.poolL = nn.MaxPool1d(input_size)\n",
    "\n",
    "        def forward(self, giant_block):\n",
    "\n",
    "            S = giant_block[:, 0,]\n",
    "\n",
    "            M = giant_block[:,1: max_event_length_week+1,].contiguous()\n",
    "\n",
    "            L = giant_block[:,max_event_length_week+1:,].contiguous()\n",
    "\n",
    "            #--------------------LARGE\n",
    "\n",
    "            out_L = self.convL(L)\n",
    "            out_L = self.poolL(out_L)\n",
    "            out_L = out_L.view(-1, hidden_size_convL)\n",
    "            #-------------------LARGE\n",
    "\n",
    "            #------------------- MIDDLE\n",
    "            out_M = self.convM(M)\n",
    "            out_M = self.poolM(out_M)\n",
    "            out_M = out_M.view(-1, hidden_size_convM)\n",
    "            #-------------------MIDDLE\n",
    "\n",
    "\n",
    "            #x = concatenation S, M, L\n",
    "            x = torch.cat((out_L, out_M,S, ), 1) \n",
    "\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out)\n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader_total):\n",
    "\n",
    "            inp = Variable(inp, requires_grad=True)\n",
    "            outp = Variable(outp)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader_total:\n",
    "        inp = Variable(inp)\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader_total:\n",
    "        inp = Variable(inp, requires_grad=True )\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "\n",
    "    return (str(train_accuracy)[0:5], str(test_accuracy)[0:5] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0', '0.454')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_embedding_to_class('AAPL', 0.7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = ['GOOGL', 'INTC', 'AAPL', 'CSCO', 'QCOM', 'NVDA', 'AMZN', 'MSFT']\n",
    "stk_lst = []\n",
    "\n",
    "training_ratio_population = [0.1*float(i) for i in range(5,10)]\n",
    "training_ratio_names = [str(0.1*float(i)) + \" Training Ratio\" for i in range(5,10) ]\n",
    "for stock in population:\n",
    "    stock_length = {}\n",
    "    for j in range(len(training_ratio_population)):\n",
    "        stock_length[training_ratio_names[j]] = total_embedding_to_class(stock, training_ratio_population[j], False)\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>0.5 Training Ratio</th>\n",
       "      <th>0.6 Training Ratio</th>\n",
       "      <th>0.7 Training Ratio</th>\n",
       "      <th>0.8 Training Ratio</th>\n",
       "      <th>0.9 Training Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>(0.762, 0.520)</td>\n",
       "      <td>(0.768, 0.516)</td>\n",
       "      <td>(0.786, 0.465)</td>\n",
       "      <td>(0.704, 0.519)</td>\n",
       "      <td>(0.697, 0.447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>(0.689, 0.5)</td>\n",
       "      <td>(0.777, 0.523)</td>\n",
       "      <td>(0.733, 0.531)</td>\n",
       "      <td>(0.723, 0.484)</td>\n",
       "      <td>(0.709, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>(0.869, 0.475)</td>\n",
       "      <td>(0.919, 0.500)</td>\n",
       "      <td>(0.850, 0.459)</td>\n",
       "      <td>(0.919, 0.466)</td>\n",
       "      <td>(0.923, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>(0.663, 0.604)</td>\n",
       "      <td>(0.654, 0.602)</td>\n",
       "      <td>(0.640, 0.6)</td>\n",
       "      <td>(0.659, 0.5)</td>\n",
       "      <td>(0.618, 0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>(0.586, 0.568)</td>\n",
       "      <td>(0.618, 0.559)</td>\n",
       "      <td>(0.582, 0.579)</td>\n",
       "      <td>(0.596, 0.478)</td>\n",
       "      <td>(0.593, 0.391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0.642, 0.571)</td>\n",
       "      <td>(0.705, 0.454)</td>\n",
       "      <td>(0.65, 0.5)</td>\n",
       "      <td>(0.652, 0.4)</td>\n",
       "      <td>(0.653, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>(0.721, 0.574)</td>\n",
       "      <td>(0.626, 0.491)</td>\n",
       "      <td>(0.711, 0.557)</td>\n",
       "      <td>(0.666, 0.406)</td>\n",
       "      <td>(0.778, 0.453)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>(0.701, 0.536)</td>\n",
       "      <td>(0.743, 0.518)</td>\n",
       "      <td>(0.749, 0.538)</td>\n",
       "      <td>(0.745, 0.495)</td>\n",
       "      <td>(0.737, 0.483)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name 0.5 Training Ratio 0.6 Training Ratio 0.7 Training Ratio  \\\n",
       "0      GOOGL     (0.762, 0.520)     (0.768, 0.516)     (0.786, 0.465)   \n",
       "1       INTC       (0.689, 0.5)     (0.777, 0.523)     (0.733, 0.531)   \n",
       "2       AAPL     (0.869, 0.475)     (0.919, 0.500)     (0.850, 0.459)   \n",
       "3       CSCO     (0.663, 0.604)     (0.654, 0.602)       (0.640, 0.6)   \n",
       "4       QCOM     (0.586, 0.568)     (0.618, 0.559)     (0.582, 0.579)   \n",
       "5       NVDA     (0.642, 0.571)     (0.705, 0.454)        (0.65, 0.5)   \n",
       "6       AMZN     (0.721, 0.574)     (0.626, 0.491)     (0.711, 0.557)   \n",
       "7       MSFT     (0.701, 0.536)     (0.743, 0.518)     (0.749, 0.538)   \n",
       "\n",
       "  0.8 Training Ratio 0.9 Training Ratio  \n",
       "0     (0.704, 0.519)     (0.697, 0.447)  \n",
       "1     (0.723, 0.484)       (0.709, 0.5)  \n",
       "2     (0.919, 0.466)       (0.923, 0.5)  \n",
       "3       (0.659, 0.5)     (0.618, 0.722)  \n",
       "4     (0.596, 0.478)     (0.593, 0.391)  \n",
       "5       (0.652, 0.4)       (0.653, 0.5)  \n",
       "6     (0.666, 0.406)     (0.778, 0.453)  \n",
       "7     (0.745, 0.495)     (0.737, 0.483)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\"] + training_ratio_names  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = ['GOOGL', 'INTC', 'AAPL', 'CSCO', 'QCOM', 'NVDA', 'AMZN', 'MSFT']\n",
    "stk_lst = []\n",
    "\n",
    "training_ratio_population = [0.1*float(i) for i in range(5,10)]\n",
    "training_ratio_names = [str(0.1*float(i)) + \" Training Ratio\" for i in range(5,10) ]\n",
    "for stock in population:\n",
    "    stock_length = {}\n",
    "    for j in range(len(training_ratio_population)):\n",
    "        stock_length[training_ratio_names[j]] = short_term_embedding_to_class(stock, 1, training_ratio_population[j], False)\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>0.5 Training Ratio</th>\n",
       "      <th>0.6 Training Ratio</th>\n",
       "      <th>0.7 Training Ratio</th>\n",
       "      <th>0.8 Training Ratio</th>\n",
       "      <th>0.9 Training Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>(0.737, 0.551)</td>\n",
       "      <td>(0.545, 0.458)</td>\n",
       "      <td>(0.680, 0.474)</td>\n",
       "      <td>(0.636, 0.467)</td>\n",
       "      <td>(0.631, 0.394)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>(0.534, 0.468)</td>\n",
       "      <td>(0.544, 0.437)</td>\n",
       "      <td>(0.68, 0.510)</td>\n",
       "      <td>(0.587, 0.437)</td>\n",
       "      <td>(0.633, 0.437)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>(0.6, 0.501)</td>\n",
       "      <td>(0.588, 0.499)</td>\n",
       "      <td>(0.594, 0.484)</td>\n",
       "      <td>(0.589, 0.456)</td>\n",
       "      <td>(0.582, 0.461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>(0.663, 0.604)</td>\n",
       "      <td>(0.654, 0.602)</td>\n",
       "      <td>(0.640, 0.6)</td>\n",
       "      <td>(0.659, 0.5)</td>\n",
       "      <td>(0.618, 0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>(0.586, 0.568)</td>\n",
       "      <td>(0.561, 0.591)</td>\n",
       "      <td>(0.546, 0.637)</td>\n",
       "      <td>(0.596, 0.478)</td>\n",
       "      <td>(0.593, 0.391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0.642, 0.571)</td>\n",
       "      <td>(0.705, 0.454)</td>\n",
       "      <td>(0.65, 0.5)</td>\n",
       "      <td>(0.652, 0.4)</td>\n",
       "      <td>(0.615, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>(0.655, 0.494)</td>\n",
       "      <td>(0.619, 0.461)</td>\n",
       "      <td>(0.647, 0.5)</td>\n",
       "      <td>(0.555, 0.38)</td>\n",
       "      <td>(0.638, 0.573)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>(0.580, 0.476)</td>\n",
       "      <td>(0.674, 0.530)</td>\n",
       "      <td>(0.679, 0.532)</td>\n",
       "      <td>(0.651, 0.570)</td>\n",
       "      <td>(0.655, 0.566)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name 0.5 Training Ratio 0.6 Training Ratio 0.7 Training Ratio  \\\n",
       "0      GOOGL     (0.737, 0.551)     (0.545, 0.458)     (0.680, 0.474)   \n",
       "1       INTC     (0.534, 0.468)     (0.544, 0.437)      (0.68, 0.510)   \n",
       "2       AAPL       (0.6, 0.501)     (0.588, 0.499)     (0.594, 0.484)   \n",
       "3       CSCO     (0.663, 0.604)     (0.654, 0.602)       (0.640, 0.6)   \n",
       "4       QCOM     (0.586, 0.568)     (0.561, 0.591)     (0.546, 0.637)   \n",
       "5       NVDA     (0.642, 0.571)     (0.705, 0.454)        (0.65, 0.5)   \n",
       "6       AMZN     (0.655, 0.494)     (0.619, 0.461)       (0.647, 0.5)   \n",
       "7       MSFT     (0.580, 0.476)     (0.674, 0.530)     (0.679, 0.532)   \n",
       "\n",
       "  0.8 Training Ratio 0.9 Training Ratio  \n",
       "0     (0.636, 0.467)     (0.631, 0.394)  \n",
       "1     (0.587, 0.437)     (0.633, 0.437)  \n",
       "2     (0.589, 0.456)     (0.582, 0.461)  \n",
       "3       (0.659, 0.5)     (0.618, 0.722)  \n",
       "4     (0.596, 0.478)     (0.593, 0.391)  \n",
       "5       (0.652, 0.4)       (0.615, 0.5)  \n",
       "6      (0.555, 0.38)     (0.638, 0.573)  \n",
       "7     (0.651, 0.570)     (0.655, 0.566)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\"] + training_ratio_names  ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
