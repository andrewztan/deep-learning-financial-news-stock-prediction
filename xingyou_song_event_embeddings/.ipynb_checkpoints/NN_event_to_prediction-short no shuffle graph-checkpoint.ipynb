{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import nltk \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "from datetime import date\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "with open('word_embeddings/run_info.p', 'r') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "info2index = x['info2index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "event_embeddings = pd.read_csv(\"word_embeddings/u_epoch_500.csv\", header = None)\n",
    "embedding_lst = []\n",
    "for row in event_embeddings.iterrows():\n",
    "    index, data = row \n",
    "    temp = data.tolist()\n",
    "    actual_data = [float(x) for x in temp[0].split()]\n",
    "    embedding_lst.append(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_to_month = {\"01\": \"Jan\", \"02\":\"Feb\", \"03\":\"Mar\", \"04\":\"Apr\", \"05\":\"May\", \"06\": \"Jun\", \"07\":\"Jul\", \"08\":\"Aug\", \"09\":\"Sep\", \"10\":\"Oct\", \"11\":\"Nov\", \"12\":\"Dec\"}\n",
    "def conv_num_to_string(d): #ex: conv_num_to_string('20041001') = '01-Oct-04'\n",
    "    year = d[0:4]\n",
    "    month = d[4:6]\n",
    "    day = d[6:8]\n",
    "    new = day + \"-\" + number_to_month[month] + \"-\" + year[2:4]\n",
    "    return new \n",
    "\n",
    "def numeric_day_distance(day1, day2): #'20140111', '20150115'\n",
    "    d0 = date(int(day1[0:4]), int(day1[4:6]), int(day1[6:8]) )\n",
    "    d1 = date(int(day2[0:4]), int(day2[4:6]), int(day2[6:8]) )\n",
    "    delta = d0 - d1 \n",
    "    return abs(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stock_to_events = {}\n",
    "for key_ in info2index:\n",
    "    stock_ = key_[0]\n",
    "    embedding_to_index = info2index[key_]\n",
    "    date_ = key_[1]\n",
    "    event = key_[2]\n",
    "    new_value = [date_, embedding_to_index]\n",
    "    if stock_ in stock_to_events: \n",
    "        stock_to_events[stock_].append(new_value)\n",
    "    else:\n",
    "        stock_to_events[stock_] = [new_value]\n",
    "\n",
    "for stock_ in stock_to_events:\n",
    "    stock_to_events[stock_] = sorted( stock_to_events[stock_], key = lambda x: x[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOOGL', 'INTC', 'AAPL', 'CSCO', 'AMD', 'QCOM', 'NVDA', 'AMZN', 'MSFT', 'IBM']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_to_events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    stock_length = {}\n",
    "    stock_length[\"Number of Articles\"] = len(stock_to_events[stock])\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Number of Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IBM</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Number of Articles\n",
       "0      GOOGL                 528\n",
       "1       INTC                 409\n",
       "2       AAPL                2292\n",
       "3       CSCO                 229\n",
       "4        AMD                  23\n",
       "5       QCOM                 351\n",
       "6       NVDA                  54\n",
       "7       AMZN                1062\n",
       "8       MSFT                 830\n",
       "9        IBM                 415"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ [\"Stock Name\", \"Number of Articles\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def up_down_ratio(stock, day_lag): #ex: sentiment_to_price_plot(\"AAPL\", 1, 'neg')\n",
    "    stock_data = news_csv[news_csv[\"stock\"] == stock]\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    total = []\n",
    "    for index, row in stock_data.iterrows():\n",
    "    \n",
    "\n",
    "        day = conv_num_to_string(str(row[\"date\"]) )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            \n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            #print next_price[\"Date\"], google_price_csv.iloc[row_index][\"Date\"]\n",
    "            diff = next_price[\"Close\"] - next_price[\"Open\"]\n",
    "            if diff >= 0.0:\n",
    "                total.append(1) \n",
    "            else:\n",
    "                total.append(0)\n",
    "    return 100*sum(total)/len(total)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    if stock != 'IBM':\n",
    "        stock_length = {}\n",
    "        stock_length[\"Price Up Percentage\"] = up_down_ratio(stock, 1)\n",
    "        stock_length[\"Stock Name\"] = stock\n",
    "        stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Price Up Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Price Up Percentage\n",
       "0      GOOGL                   49\n",
       "1       INTC                   49\n",
       "2       AAPL                   48\n",
       "3       CSCO                   60\n",
       "4        AMD                   50\n",
       "5       QCOM                   45\n",
       "6       NVDA                   72\n",
       "7       AMZN                   48\n",
       "8       MSFT                   51"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\", \"Price Up Percentage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])\n",
    "google_price_csv = pd.read_csv(\"price_data/GOOGL_2006-01-01_to_2017-11-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def short_term_embedding_to_class(stock, day_lag, training_ratio, shuff_bool, epoch_size):\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for event in stock_to_events[stock]:\n",
    "        \n",
    "        \n",
    "        day = conv_num_to_string( event[0]    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp_x.append( embedding_lst[event[1]]  )\n",
    "            \n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            \n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "            \n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------\n",
    "    \n",
    "    input_size = 100\n",
    "    hidden_size = 150\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = epoch_size\n",
    "    batch_size = 100\n",
    "    \n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "    \n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "    \n",
    "    train_x = torch.FloatTensor(train_x)\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    \n",
    "    \n",
    "    test_x = torch.FloatTensor(test_x)\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    \n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=shuff_bool)\n",
    "    \n",
    "    \n",
    "    test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "    \n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size, hidden_size)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out) \n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, hidden_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader):\n",
    "            \n",
    "            inp = Variable(inp)\n",
    "            outp = Variable(outp)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            \n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "    \n",
    "    return (str(train_accuracy)[0:5], str(test_accuracy)[0:5] )\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.835', '0.551')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_term_embedding_to_class('GOOGL', 1, 0.5, False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "x_axis = range(10,510,10)\n",
    "training_acc = []\n",
    "test_acc =[]\n",
    "for e in x_axis:\n",
    "    print e\n",
    "    output = short_term_embedding_to_class('AAPL', 1, 0.7, False, e)\n",
    "    first = float(output[0])\n",
    "    second = float(output[1])\n",
    "    training_acc.append(first)\n",
    "    test_acc.append(second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxEJOAW9iEjAKehFRALuvwEKjZIJ1rbXPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e1a0043d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab\n",
    "pylab.plot(x_axis,training_acc, 'r', label = 'training acc')\n",
    "pylab.plot(x_axis, test_acc, 'b', label = 'test acc')\n",
    "pylab.legend(loc = 'lower left')\n",
    "pylab.xlim(10, 500)\n",
    "pylab.ylim(0.0,1.0)\n",
    "pylab.title(\"Short Term Network No Shuffling on AAPL\")\n",
    "pylab.xlabel(\"Epoch Size\")\n",
    "pylab.ylabel(\"Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def total_embedding_to_class(stock, training_ratio, shuff_bool): \n",
    "\n",
    "\n",
    "    #----------------------------LAGS\n",
    "    day_lag = 1 \n",
    "    week_lag = 7\n",
    "    month_lag = 30\n",
    "    #--------------------------- NN parameters\n",
    "    input_size = 100\n",
    "    window_size_convM =3\n",
    "    hidden_size_convM = 20\n",
    "\n",
    "    window_size_convL =3 \n",
    "    hidden_size_convL = 40\n",
    "\n",
    "\n",
    "    hidden_size_end = 200\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 500\n",
    "    batch_size = 50\n",
    "\n",
    "    #training_ratio = 0.8\n",
    "    #stock = 'AAPL'\n",
    "\n",
    "    #----------------------------------- PARAMTETRS\n",
    "\n",
    "\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for i in range(len(stock_to_events[stock]) ):\n",
    "        event = stock_to_events[stock][i]\n",
    "\n",
    "\n",
    "        date_numeric = event[0]\n",
    "        day = conv_num_to_string( date_numeric    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp = {}\n",
    "            temp[\"day\"] = embedding_lst[event[1]]\n",
    "\n",
    "\n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "\n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "\n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "\n",
    "\n",
    "\n",
    "            temp[\"week\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= week_lag ) :\n",
    "                temp['week'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "\n",
    "            temp[\"month\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= month_lag ) :\n",
    "                temp['month'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "            temp_x.append(temp)\n",
    "    #--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "\n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "\n",
    "\n",
    "    max_event_length_week = max([len(day_embedding[\"week\"]) for day_embedding in temp_x ])\n",
    "    max_event_length_month = max([len(day_embedding[\"month\"]) for day_embedding in temp_x ])\n",
    "\n",
    "\n",
    "    train_x_concatenate = []\n",
    "\n",
    "\n",
    "\n",
    "    for day_embedding in train_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        train_x_concatenate.append(block)\n",
    "\n",
    "    train_x_concatenate = torch.FloatTensor(train_x_concatenate)\n",
    "\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    train_x_concatenate_temp = torch.utils.data.TensorDataset(train_x_concatenate, train_y)\n",
    "    train_loader_total = torch.utils.data.DataLoader(dataset=train_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=shuff_bool)\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------\n",
    "\n",
    "    test_x_concatenate = []\n",
    "\n",
    "\n",
    "    for day_embedding in test_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        test_x_concatenate.append(block)\n",
    "\n",
    "\n",
    "    test_x_concatenate = torch.FloatTensor(test_x_concatenate)\n",
    "\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    test_x_concatenate_temp = torch.utils.data.TensorDataset(test_x_concatenate, test_y)\n",
    "    test_loader_total = torch.utils.data.DataLoader(dataset=test_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size + hidden_size_convM + hidden_size_convL , hidden_size_end)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size_end, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "\n",
    "            self.convM = nn.Conv1d(max_event_length_week, hidden_size_convM, window_size_convM, padding = 1 )\n",
    "            self.poolM = nn.MaxPool1d(input_size)\n",
    "\n",
    "            self.convL = nn.Conv1d(max_event_length_month, hidden_size_convL, window_size_convL, padding = 1 )\n",
    "            self.poolL = nn.MaxPool1d(input_size)\n",
    "\n",
    "        def forward(self, giant_block):\n",
    "\n",
    "            S = giant_block[:, 0,]\n",
    "\n",
    "            M = giant_block[:,1: max_event_length_week+1,].contiguous()\n",
    "\n",
    "            L = giant_block[:,max_event_length_week+1:,].contiguous()\n",
    "\n",
    "            #--------------------LARGE\n",
    "\n",
    "            out_L = self.convL(L)\n",
    "            out_L = self.poolL(out_L)\n",
    "            out_L = out_L.view(-1, hidden_size_convL)\n",
    "            #-------------------LARGE\n",
    "\n",
    "            #------------------- MIDDLE\n",
    "            out_M = self.convM(M)\n",
    "            out_M = self.poolM(out_M)\n",
    "            out_M = out_M.view(-1, hidden_size_convM)\n",
    "            #-------------------MIDDLE\n",
    "\n",
    "\n",
    "            #x = concatenation S, M, L\n",
    "            x = torch.cat((out_L, out_M,S, ), 1) \n",
    "\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out)\n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader_total):\n",
    "\n",
    "            inp = Variable(inp, requires_grad=True)\n",
    "            outp = Variable(outp)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader_total:\n",
    "        inp = Variable(inp)\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader_total:\n",
    "        inp = Variable(inp, requires_grad=True )\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "\n",
    "    return (str(train_accuracy)[0:5], str(test_accuracy)[0:5] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0', '0.454')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_embedding_to_class('AAPL', 0.7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = ['GOOGL', 'INTC', 'AAPL', 'CSCO', 'QCOM', 'NVDA', 'AMZN', 'MSFT']\n",
    "stk_lst = []\n",
    "\n",
    "training_ratio_population = [0.1*float(i) for i in range(5,10)]\n",
    "training_ratio_names = [str(0.1*float(i)) + \" Training Ratio\" for i in range(5,10) ]\n",
    "for stock in population:\n",
    "    stock_length = {}\n",
    "    for j in range(len(training_ratio_population)):\n",
    "        stock_length[training_ratio_names[j]] = total_embedding_to_class(stock, training_ratio_population[j], False)\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>0.5 Training Ratio</th>\n",
       "      <th>0.6 Training Ratio</th>\n",
       "      <th>0.7 Training Ratio</th>\n",
       "      <th>0.8 Training Ratio</th>\n",
       "      <th>0.9 Training Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>(0.762, 0.520)</td>\n",
       "      <td>(0.768, 0.516)</td>\n",
       "      <td>(0.786, 0.465)</td>\n",
       "      <td>(0.704, 0.519)</td>\n",
       "      <td>(0.697, 0.447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>(0.689, 0.5)</td>\n",
       "      <td>(0.777, 0.523)</td>\n",
       "      <td>(0.733, 0.531)</td>\n",
       "      <td>(0.723, 0.484)</td>\n",
       "      <td>(0.709, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>(0.869, 0.475)</td>\n",
       "      <td>(0.919, 0.500)</td>\n",
       "      <td>(0.850, 0.459)</td>\n",
       "      <td>(0.919, 0.466)</td>\n",
       "      <td>(0.923, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>(0.663, 0.604)</td>\n",
       "      <td>(0.654, 0.602)</td>\n",
       "      <td>(0.640, 0.6)</td>\n",
       "      <td>(0.659, 0.5)</td>\n",
       "      <td>(0.618, 0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>(0.586, 0.568)</td>\n",
       "      <td>(0.618, 0.559)</td>\n",
       "      <td>(0.582, 0.579)</td>\n",
       "      <td>(0.596, 0.478)</td>\n",
       "      <td>(0.593, 0.391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0.642, 0.571)</td>\n",
       "      <td>(0.705, 0.454)</td>\n",
       "      <td>(0.65, 0.5)</td>\n",
       "      <td>(0.652, 0.4)</td>\n",
       "      <td>(0.653, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>(0.721, 0.574)</td>\n",
       "      <td>(0.626, 0.491)</td>\n",
       "      <td>(0.711, 0.557)</td>\n",
       "      <td>(0.666, 0.406)</td>\n",
       "      <td>(0.778, 0.453)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>(0.701, 0.536)</td>\n",
       "      <td>(0.743, 0.518)</td>\n",
       "      <td>(0.749, 0.538)</td>\n",
       "      <td>(0.745, 0.495)</td>\n",
       "      <td>(0.737, 0.483)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name 0.5 Training Ratio 0.6 Training Ratio 0.7 Training Ratio  \\\n",
       "0      GOOGL     (0.762, 0.520)     (0.768, 0.516)     (0.786, 0.465)   \n",
       "1       INTC       (0.689, 0.5)     (0.777, 0.523)     (0.733, 0.531)   \n",
       "2       AAPL     (0.869, 0.475)     (0.919, 0.500)     (0.850, 0.459)   \n",
       "3       CSCO     (0.663, 0.604)     (0.654, 0.602)       (0.640, 0.6)   \n",
       "4       QCOM     (0.586, 0.568)     (0.618, 0.559)     (0.582, 0.579)   \n",
       "5       NVDA     (0.642, 0.571)     (0.705, 0.454)        (0.65, 0.5)   \n",
       "6       AMZN     (0.721, 0.574)     (0.626, 0.491)     (0.711, 0.557)   \n",
       "7       MSFT     (0.701, 0.536)     (0.743, 0.518)     (0.749, 0.538)   \n",
       "\n",
       "  0.8 Training Ratio 0.9 Training Ratio  \n",
       "0     (0.704, 0.519)     (0.697, 0.447)  \n",
       "1     (0.723, 0.484)       (0.709, 0.5)  \n",
       "2     (0.919, 0.466)       (0.923, 0.5)  \n",
       "3       (0.659, 0.5)     (0.618, 0.722)  \n",
       "4     (0.596, 0.478)     (0.593, 0.391)  \n",
       "5       (0.652, 0.4)       (0.653, 0.5)  \n",
       "6     (0.666, 0.406)     (0.778, 0.453)  \n",
       "7     (0.745, 0.495)     (0.737, 0.483)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\"] + training_ratio_names  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = ['GOOGL', 'INTC', 'AAPL', 'CSCO', 'QCOM', 'NVDA', 'AMZN', 'MSFT']\n",
    "stk_lst = []\n",
    "\n",
    "training_ratio_population = [0.1*float(i) for i in range(5,10)]\n",
    "training_ratio_names = [str(0.1*float(i)) + \" Training Ratio\" for i in range(5,10) ]\n",
    "for stock in population:\n",
    "    stock_length = {}\n",
    "    for j in range(len(training_ratio_population)):\n",
    "        stock_length[training_ratio_names[j]] = short_term_embedding_to_class(stock, 1, training_ratio_population[j], False)\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>0.5 Training Ratio</th>\n",
       "      <th>0.6 Training Ratio</th>\n",
       "      <th>0.7 Training Ratio</th>\n",
       "      <th>0.8 Training Ratio</th>\n",
       "      <th>0.9 Training Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>(0.737, 0.551)</td>\n",
       "      <td>(0.545, 0.458)</td>\n",
       "      <td>(0.680, 0.474)</td>\n",
       "      <td>(0.636, 0.467)</td>\n",
       "      <td>(0.631, 0.394)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>(0.534, 0.468)</td>\n",
       "      <td>(0.544, 0.437)</td>\n",
       "      <td>(0.68, 0.510)</td>\n",
       "      <td>(0.587, 0.437)</td>\n",
       "      <td>(0.633, 0.437)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>(0.6, 0.501)</td>\n",
       "      <td>(0.588, 0.499)</td>\n",
       "      <td>(0.594, 0.484)</td>\n",
       "      <td>(0.589, 0.456)</td>\n",
       "      <td>(0.582, 0.461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>(0.663, 0.604)</td>\n",
       "      <td>(0.654, 0.602)</td>\n",
       "      <td>(0.640, 0.6)</td>\n",
       "      <td>(0.659, 0.5)</td>\n",
       "      <td>(0.618, 0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>(0.586, 0.568)</td>\n",
       "      <td>(0.561, 0.591)</td>\n",
       "      <td>(0.546, 0.637)</td>\n",
       "      <td>(0.596, 0.478)</td>\n",
       "      <td>(0.593, 0.391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0.642, 0.571)</td>\n",
       "      <td>(0.705, 0.454)</td>\n",
       "      <td>(0.65, 0.5)</td>\n",
       "      <td>(0.652, 0.4)</td>\n",
       "      <td>(0.615, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>(0.655, 0.494)</td>\n",
       "      <td>(0.619, 0.461)</td>\n",
       "      <td>(0.647, 0.5)</td>\n",
       "      <td>(0.555, 0.38)</td>\n",
       "      <td>(0.638, 0.573)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>(0.580, 0.476)</td>\n",
       "      <td>(0.674, 0.530)</td>\n",
       "      <td>(0.679, 0.532)</td>\n",
       "      <td>(0.651, 0.570)</td>\n",
       "      <td>(0.655, 0.566)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name 0.5 Training Ratio 0.6 Training Ratio 0.7 Training Ratio  \\\n",
       "0      GOOGL     (0.737, 0.551)     (0.545, 0.458)     (0.680, 0.474)   \n",
       "1       INTC     (0.534, 0.468)     (0.544, 0.437)      (0.68, 0.510)   \n",
       "2       AAPL       (0.6, 0.501)     (0.588, 0.499)     (0.594, 0.484)   \n",
       "3       CSCO     (0.663, 0.604)     (0.654, 0.602)       (0.640, 0.6)   \n",
       "4       QCOM     (0.586, 0.568)     (0.561, 0.591)     (0.546, 0.637)   \n",
       "5       NVDA     (0.642, 0.571)     (0.705, 0.454)        (0.65, 0.5)   \n",
       "6       AMZN     (0.655, 0.494)     (0.619, 0.461)       (0.647, 0.5)   \n",
       "7       MSFT     (0.580, 0.476)     (0.674, 0.530)     (0.679, 0.532)   \n",
       "\n",
       "  0.8 Training Ratio 0.9 Training Ratio  \n",
       "0     (0.636, 0.467)     (0.631, 0.394)  \n",
       "1     (0.587, 0.437)     (0.633, 0.437)  \n",
       "2     (0.589, 0.456)     (0.582, 0.461)  \n",
       "3       (0.659, 0.5)     (0.618, 0.722)  \n",
       "4     (0.596, 0.478)     (0.593, 0.391)  \n",
       "5       (0.652, 0.4)       (0.615, 0.5)  \n",
       "6      (0.555, 0.38)     (0.638, 0.573)  \n",
       "7     (0.651, 0.570)     (0.655, 0.566)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\"] + training_ratio_names  ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
