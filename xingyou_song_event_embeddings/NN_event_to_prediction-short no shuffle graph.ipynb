{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import nltk \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as st\n",
    "from datetime import date\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "with open('word_embeddings/run_info.p', 'r') as f:\n",
    "    x = pickle.load(f)\n",
    "\n",
    "info2index = x['info2index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "event_embeddings = pd.read_csv(\"word_embeddings/u_epoch_500.csv\", header = None)\n",
    "embedding_lst = []\n",
    "for row in event_embeddings.iterrows():\n",
    "    index, data = row \n",
    "    temp = data.tolist()\n",
    "    actual_data = [float(x) for x in temp[0].split()]\n",
    "    embedding_lst.append(actual_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "number_to_month = {\"01\": \"Jan\", \"02\":\"Feb\", \"03\":\"Mar\", \"04\":\"Apr\", \"05\":\"May\", \"06\": \"Jun\", \"07\":\"Jul\", \"08\":\"Aug\", \"09\":\"Sep\", \"10\":\"Oct\", \"11\":\"Nov\", \"12\":\"Dec\"}\n",
    "def conv_num_to_string(d): #ex: conv_num_to_string('20041001') = '01-Oct-04'\n",
    "    year = d[0:4]\n",
    "    month = d[4:6]\n",
    "    day = d[6:8]\n",
    "    new = day + \"-\" + number_to_month[month] + \"-\" + year[2:4]\n",
    "    return new \n",
    "\n",
    "def numeric_day_distance(day1, day2): #'20140111', '20150115'\n",
    "    d0 = date(int(day1[0:4]), int(day1[4:6]), int(day1[6:8]) )\n",
    "    d1 = date(int(day2[0:4]), int(day2[4:6]), int(day2[6:8]) )\n",
    "    delta = d0 - d1 \n",
    "    return abs(delta.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "stock_to_events = {}\n",
    "for key_ in info2index:\n",
    "    stock_ = key_[0]\n",
    "    embedding_to_index = info2index[key_]\n",
    "    date_ = key_[1]\n",
    "    event = key_[2]\n",
    "    new_value = [date_, embedding_to_index]\n",
    "    if stock_ in stock_to_events: \n",
    "        stock_to_events[stock_].append(new_value)\n",
    "    else:\n",
    "        stock_to_events[stock_] = [new_value]\n",
    "\n",
    "for stock_ in stock_to_events:\n",
    "    stock_to_events[stock_] = sorted( stock_to_events[stock_], key = lambda x: x[0]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOOGL', 'INTC', 'AAPL', 'CSCO', 'AMD', 'QCOM', 'NVDA', 'AMZN', 'MSFT', 'IBM']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_to_events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    stock_length = {}\n",
    "    stock_length[\"Number of Articles\"] = len(stock_to_events[stock])\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Number of Articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IBM</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Number of Articles\n",
       "0      GOOGL                 528\n",
       "1       INTC                 409\n",
       "2       AAPL                2292\n",
       "3       CSCO                 229\n",
       "4        AMD                  23\n",
       "5       QCOM                 351\n",
       "6       NVDA                  54\n",
       "7       AMZN                1062\n",
       "8       MSFT                 830\n",
       "9        IBM                 415"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ [\"Stock Name\", \"Number of Articles\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def up_down_ratio(stock, day_lag): #ex: sentiment_to_price_plot(\"AAPL\", 1, 'neg')\n",
    "    stock_data = news_csv[news_csv[\"stock\"] == stock]\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    total = []\n",
    "    for index, row in stock_data.iterrows():\n",
    "    \n",
    "\n",
    "        day = conv_num_to_string(str(row[\"date\"]) )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            \n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            #print next_price[\"Date\"], google_price_csv.iloc[row_index][\"Date\"]\n",
    "            diff = next_price[\"Close\"] - next_price[\"Open\"]\n",
    "            if diff >= 0.0:\n",
    "                total.append(1) \n",
    "            else:\n",
    "                total.append(0)\n",
    "    return 100*sum(total)/len(total)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stk_lst = []\n",
    "\n",
    "for stock in stock_to_events:\n",
    "    if stock != 'IBM':\n",
    "        stock_length = {}\n",
    "        stock_length[\"Price Up Percentage\"] = up_down_ratio(stock, 1)\n",
    "        stock_length[\"Stock Name\"] = stock\n",
    "        stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Price Up Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMD</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name  Price Up Percentage\n",
       "0      GOOGL                   49\n",
       "1       INTC                   49\n",
       "2       AAPL                   48\n",
       "3       CSCO                   60\n",
       "4        AMD                   50\n",
       "5       QCOM                   45\n",
       "6       NVDA                   72\n",
       "7       AMZN                   48\n",
       "8       MSFT                   51"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\", \"Price Up Percentage\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "news_csv = pd.read_csv(\"news_data/news_reuters_10.csv\", error_bad_lines=False, header = None, names = [\"stock\", \"company\", \"date\", \"title\", \"summary\", \"type\", \"website\"])\n",
    "google_price_csv = pd.read_csv(\"price_data/GOOGL_2006-01-01_to_2017-11-01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def short_term_embedding_to_class(stock, day_lag, training_ratio, shuff_bool, epoch_size):\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for event in stock_to_events[stock]:\n",
    "        \n",
    "        \n",
    "        day = conv_num_to_string( event[0]    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp_x.append( embedding_lst[event[1]]  )\n",
    "            \n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "            \n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "            \n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "    \n",
    "    \n",
    "    #--------------------------------------\n",
    "    \n",
    "    input_size = 100\n",
    "    hidden_size = 150\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = epoch_size\n",
    "    batch_size = 100\n",
    "    \n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "    \n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "    \n",
    "    train_x = torch.FloatTensor(train_x)\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    \n",
    "    \n",
    "    test_x = torch.FloatTensor(test_x)\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    \n",
    "    #-------------------------------------\n",
    "    \n",
    "    \n",
    "    train = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=shuff_bool)\n",
    "    \n",
    "    \n",
    "    test = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "    \n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size, hidden_size)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "            \n",
    "        def forward(self, x):\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out) \n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, hidden_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader):\n",
    "            \n",
    "            inp = Variable(inp)\n",
    "            outp = Variable(outp)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            \n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader:\n",
    "        inp = Variable(inp)\n",
    "        \n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "    \n",
    "    return (str(train_accuracy)[0:5], str(test_accuracy)[0:5] )\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.835', '0.551')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_term_embedding_to_class('GOOGL', 1, 0.5, False, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "x_axis = range(10,510,10)\n",
    "training_acc = []\n",
    "test_acc =[]\n",
    "for e in x_axis:\n",
    "    print e\n",
    "    output = short_term_embedding_to_class('AAPL', 1, 0.7, False, e)\n",
    "    first = float(output[0])\n",
    "    second = float(output[1])\n",
    "    training_acc.append(first)\n",
    "    test_acc.append(second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEZCAYAAABiu9n+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e1a1f5090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab\n",
    "pylab.plot(x_axis,training_acc, 'r', label = 'training acc')\n",
    "pylab.plot(x_axis, test_acc, 'b', label = 'test acc')\n",
    "pylab.legend(loc = 'lower left')\n",
    "pylab.xlim(10, 500)\n",
    "pylab.ylim(0.0,1.0)\n",
    "pylab.title(\"Short Term Network No Shuffling on AAPL\")\n",
    "pylab.xlabel(\"Epoch Size\")\n",
    "pylab.ylabel(\"Accuracy\")\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def total_embedding_to_class(stock, training_ratio, shuff_bool): \n",
    "\n",
    "\n",
    "    #----------------------------LAGS\n",
    "    day_lag = 1 \n",
    "    week_lag = 7\n",
    "    month_lag = 30\n",
    "    #--------------------------- NN parameters\n",
    "    input_size = 100\n",
    "    window_size_convM =3\n",
    "    hidden_size_convM = 20\n",
    "\n",
    "    window_size_convL =3 \n",
    "    hidden_size_convL = 40\n",
    "\n",
    "\n",
    "    hidden_size_end = 200\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    num_epochs = 500\n",
    "    batch_size = 50\n",
    "\n",
    "    #training_ratio = 0.8\n",
    "    #stock = 'AAPL'\n",
    "\n",
    "    #----------------------------------- PARAMTETRS\n",
    "\n",
    "\n",
    "    stock_price_csv = pd.read_csv(\"price_data/\"+ stock+\"_2006-01-01_to_2017-11-01.csv\")\n",
    "\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for i in range(len(stock_to_events[stock]) ):\n",
    "        event = stock_to_events[stock][i]\n",
    "\n",
    "\n",
    "        date_numeric = event[0]\n",
    "        day = conv_num_to_string( date_numeric    )\n",
    "\n",
    "        if day in stock_price_csv[\"Date\"].values:\n",
    "\n",
    "            temp = {}\n",
    "            temp[\"day\"] = embedding_lst[event[1]]\n",
    "\n",
    "\n",
    "\n",
    "            row_index = stock_price_csv.index[stock_price_csv[\"Date\"] == day].tolist()[0]\n",
    "            next_price_data = stock_price_csv.iloc[row_index - day_lag  ]\n",
    "\n",
    "            next_price = next_price_data[\"Close\"] - next_price_data[\"Open\"]\n",
    "\n",
    "            if next_price >= 0.0:\n",
    "                pos_neg_class = 1\n",
    "            else:\n",
    "                pos_neg_class = 0\n",
    "            temp_y.append(pos_neg_class)\n",
    "\n",
    "\n",
    "\n",
    "            temp[\"week\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= week_lag ) :\n",
    "                temp['week'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "\n",
    "            temp[\"month\"] = []\n",
    "            temp_date_before = 1\n",
    "            while ( i - temp_date_before >= 0 and numeric_day_distance(stock_to_events[stock][i-temp_date_before][0], date_numeric ) <= month_lag ) :\n",
    "                temp['month'].append(embedding_lst[stock_to_events[stock][i-temp_date_before][1]]    )\n",
    "                temp_date_before +=1 \n",
    "            temp_x.append(temp)\n",
    "    #--------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #--------------------------\n",
    "    sample_size = len(temp_x)\n",
    "    cut = int(training_ratio*float(sample_size) ) \n",
    "    train_x = temp_x[0:cut ]\n",
    "    test_x = temp_x[cut+1:]\n",
    "\n",
    "    train_y = temp_y[0:cut]\n",
    "    test_y = temp_y[cut+1:]\n",
    "\n",
    "\n",
    "    max_event_length_week = max([len(day_embedding[\"week\"]) for day_embedding in temp_x ])\n",
    "    max_event_length_month = max([len(day_embedding[\"month\"]) for day_embedding in temp_x ])\n",
    "\n",
    "\n",
    "    train_x_concatenate = []\n",
    "\n",
    "\n",
    "\n",
    "    for day_embedding in train_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        train_x_concatenate.append(block)\n",
    "\n",
    "    train_x_concatenate = torch.FloatTensor(train_x_concatenate)\n",
    "\n",
    "    train_y = torch.LongTensor(train_y)\n",
    "    train_x_concatenate_temp = torch.utils.data.TensorDataset(train_x_concatenate, train_y)\n",
    "    train_loader_total = torch.utils.data.DataLoader(dataset=train_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=shuff_bool)\n",
    "\n",
    "\n",
    "\n",
    "    #-----------------------------------\n",
    "\n",
    "    test_x_concatenate = []\n",
    "\n",
    "\n",
    "    for day_embedding in test_x: \n",
    "        block = [day_embedding[\"day\"]]\n",
    "        week_padding_number = max_event_length_week - len(day_embedding[\"week\"])\n",
    "        block = block + day_embedding[\"week\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(week_padding_number)]\n",
    "\n",
    "        month_padding_number = max_event_length_month - len(day_embedding[\"month\"])\n",
    "        block = block + day_embedding[\"month\"]\n",
    "        block = block + [[0.0 for i in range(input_size) ] for j in range(month_padding_number)]\n",
    "\n",
    "\n",
    "        test_x_concatenate.append(block)\n",
    "\n",
    "\n",
    "    test_x_concatenate = torch.FloatTensor(test_x_concatenate)\n",
    "\n",
    "    test_y = torch.LongTensor(test_y)\n",
    "    test_x_concatenate_temp = torch.utils.data.TensorDataset(test_x_concatenate, test_y)\n",
    "    test_loader_total = torch.utils.data.DataLoader(dataset=test_x_concatenate_temp, \n",
    "                                           batch_size = batch_size, \n",
    "                                           shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "    #------------------------------------------\n",
    "    class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end):\n",
    "            super(Net, self).__init__()\n",
    "\n",
    "            self.f1 = nn.Linear(input_size + hidden_size_convM + hidden_size_convL , hidden_size_end)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.f2 = nn.Linear(hidden_size_end, 2)\n",
    "            self.softmax = nn.Softmax()\n",
    "\n",
    "            self.convM = nn.Conv1d(max_event_length_week, hidden_size_convM, window_size_convM, padding = 1 )\n",
    "            self.poolM = nn.MaxPool1d(input_size)\n",
    "\n",
    "            self.convL = nn.Conv1d(max_event_length_month, hidden_size_convL, window_size_convL, padding = 1 )\n",
    "            self.poolL = nn.MaxPool1d(input_size)\n",
    "\n",
    "        def forward(self, giant_block):\n",
    "\n",
    "            S = giant_block[:, 0,]\n",
    "\n",
    "            M = giant_block[:,1: max_event_length_week+1,].contiguous()\n",
    "\n",
    "            L = giant_block[:,max_event_length_week+1:,].contiguous()\n",
    "\n",
    "            #--------------------LARGE\n",
    "\n",
    "            out_L = self.convL(L)\n",
    "            out_L = self.poolL(out_L)\n",
    "            out_L = out_L.view(-1, hidden_size_convL)\n",
    "            #-------------------LARGE\n",
    "\n",
    "            #------------------- MIDDLE\n",
    "            out_M = self.convM(M)\n",
    "            out_M = self.poolM(out_M)\n",
    "            out_M = out_M.view(-1, hidden_size_convM)\n",
    "            #-------------------MIDDLE\n",
    "\n",
    "\n",
    "            #x = concatenation S, M, L\n",
    "            x = torch.cat((out_L, out_M,S, ), 1) \n",
    "\n",
    "            out = self.f1(x)\n",
    "            out = self.sigmoid(out)\n",
    "            out = self.f2(out)\n",
    "            out = self.sigmoid(out) \n",
    "            out = self.softmax(out)\n",
    "            return out \n",
    "\n",
    "    net = Net(input_size, window_size_convM, hidden_size_convM, window_size_convL, hidden_size_convL, hidden_size_end )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inp, outp) in enumerate(train_loader_total):\n",
    "\n",
    "            inp = Variable(inp, requires_grad=True)\n",
    "            outp = Variable(outp)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inp)\n",
    "            loss = criterion(outputs, outp.squeeze()  )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in train_loader_total:\n",
    "        inp = Variable(inp)\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    train_accuracy = float(correct)/total \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inp, lab in test_loader_total:\n",
    "        inp = Variable(inp, requires_grad=True )\n",
    "\n",
    "        outputs = net(inp)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += lab.size(0)\n",
    "        correct += (predicted == lab).sum()\n",
    "\n",
    "\n",
    "    test_accuracy = float(correct)/total \n",
    "\n",
    "    return (str(train_accuracy)[0:5], str(test_accuracy)[0:5] )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0', '0.454')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_embedding_to_class('AAPL', 0.7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = ['GOOGL', 'INTC', 'AAPL', 'CSCO', 'QCOM', 'NVDA', 'AMZN', 'MSFT']\n",
    "stk_lst = []\n",
    "\n",
    "training_ratio_population = [0.1*float(i) for i in range(5,10)]\n",
    "training_ratio_names = [str(0.1*float(i)) + \" Training Ratio\" for i in range(5,10) ]\n",
    "for stock in population:\n",
    "    stock_length = {}\n",
    "    for j in range(len(training_ratio_population)):\n",
    "        stock_length[training_ratio_names[j]] = total_embedding_to_class(stock, training_ratio_population[j], False)\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>0.5 Training Ratio</th>\n",
       "      <th>0.6 Training Ratio</th>\n",
       "      <th>0.7 Training Ratio</th>\n",
       "      <th>0.8 Training Ratio</th>\n",
       "      <th>0.9 Training Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>(0.762, 0.520)</td>\n",
       "      <td>(0.768, 0.516)</td>\n",
       "      <td>(0.786, 0.465)</td>\n",
       "      <td>(0.704, 0.519)</td>\n",
       "      <td>(0.697, 0.447)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>(0.689, 0.5)</td>\n",
       "      <td>(0.777, 0.523)</td>\n",
       "      <td>(0.733, 0.531)</td>\n",
       "      <td>(0.723, 0.484)</td>\n",
       "      <td>(0.709, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>(0.869, 0.475)</td>\n",
       "      <td>(0.919, 0.500)</td>\n",
       "      <td>(0.850, 0.459)</td>\n",
       "      <td>(0.919, 0.466)</td>\n",
       "      <td>(0.923, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>(0.663, 0.604)</td>\n",
       "      <td>(0.654, 0.602)</td>\n",
       "      <td>(0.640, 0.6)</td>\n",
       "      <td>(0.659, 0.5)</td>\n",
       "      <td>(0.618, 0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>(0.586, 0.568)</td>\n",
       "      <td>(0.618, 0.559)</td>\n",
       "      <td>(0.582, 0.579)</td>\n",
       "      <td>(0.596, 0.478)</td>\n",
       "      <td>(0.593, 0.391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0.642, 0.571)</td>\n",
       "      <td>(0.705, 0.454)</td>\n",
       "      <td>(0.65, 0.5)</td>\n",
       "      <td>(0.652, 0.4)</td>\n",
       "      <td>(0.653, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>(0.721, 0.574)</td>\n",
       "      <td>(0.626, 0.491)</td>\n",
       "      <td>(0.711, 0.557)</td>\n",
       "      <td>(0.666, 0.406)</td>\n",
       "      <td>(0.778, 0.453)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>(0.701, 0.536)</td>\n",
       "      <td>(0.743, 0.518)</td>\n",
       "      <td>(0.749, 0.538)</td>\n",
       "      <td>(0.745, 0.495)</td>\n",
       "      <td>(0.737, 0.483)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name 0.5 Training Ratio 0.6 Training Ratio 0.7 Training Ratio  \\\n",
       "0      GOOGL     (0.762, 0.520)     (0.768, 0.516)     (0.786, 0.465)   \n",
       "1       INTC       (0.689, 0.5)     (0.777, 0.523)     (0.733, 0.531)   \n",
       "2       AAPL     (0.869, 0.475)     (0.919, 0.500)     (0.850, 0.459)   \n",
       "3       CSCO     (0.663, 0.604)     (0.654, 0.602)       (0.640, 0.6)   \n",
       "4       QCOM     (0.586, 0.568)     (0.618, 0.559)     (0.582, 0.579)   \n",
       "5       NVDA     (0.642, 0.571)     (0.705, 0.454)        (0.65, 0.5)   \n",
       "6       AMZN     (0.721, 0.574)     (0.626, 0.491)     (0.711, 0.557)   \n",
       "7       MSFT     (0.701, 0.536)     (0.743, 0.518)     (0.749, 0.538)   \n",
       "\n",
       "  0.8 Training Ratio 0.9 Training Ratio  \n",
       "0     (0.704, 0.519)     (0.697, 0.447)  \n",
       "1     (0.723, 0.484)       (0.709, 0.5)  \n",
       "2     (0.919, 0.466)       (0.923, 0.5)  \n",
       "3       (0.659, 0.5)     (0.618, 0.722)  \n",
       "4     (0.596, 0.478)     (0.593, 0.391)  \n",
       "5       (0.652, 0.4)       (0.653, 0.5)  \n",
       "6     (0.666, 0.406)     (0.778, 0.453)  \n",
       "7     (0.745, 0.495)     (0.737, 0.483)  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\"] + training_ratio_names  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "population = ['GOOGL', 'INTC', 'AAPL', 'CSCO', 'QCOM', 'NVDA', 'AMZN', 'MSFT']\n",
    "stk_lst = []\n",
    "\n",
    "training_ratio_population = [0.1*float(i) for i in range(5,10)]\n",
    "training_ratio_names = [str(0.1*float(i)) + \" Training Ratio\" for i in range(5,10) ]\n",
    "for stock in population:\n",
    "    stock_length = {}\n",
    "    for j in range(len(training_ratio_population)):\n",
    "        stock_length[training_ratio_names[j]] = short_term_embedding_to_class(stock, 1, training_ratio_population[j], False)\n",
    "    stock_length[\"Stock Name\"] = stock\n",
    "    stk_lst.append(stock_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>0.5 Training Ratio</th>\n",
       "      <th>0.6 Training Ratio</th>\n",
       "      <th>0.7 Training Ratio</th>\n",
       "      <th>0.8 Training Ratio</th>\n",
       "      <th>0.9 Training Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>(0.737, 0.551)</td>\n",
       "      <td>(0.545, 0.458)</td>\n",
       "      <td>(0.680, 0.474)</td>\n",
       "      <td>(0.636, 0.467)</td>\n",
       "      <td>(0.631, 0.394)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTC</td>\n",
       "      <td>(0.534, 0.468)</td>\n",
       "      <td>(0.544, 0.437)</td>\n",
       "      <td>(0.68, 0.510)</td>\n",
       "      <td>(0.587, 0.437)</td>\n",
       "      <td>(0.633, 0.437)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>(0.6, 0.501)</td>\n",
       "      <td>(0.588, 0.499)</td>\n",
       "      <td>(0.594, 0.484)</td>\n",
       "      <td>(0.589, 0.456)</td>\n",
       "      <td>(0.582, 0.461)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSCO</td>\n",
       "      <td>(0.663, 0.604)</td>\n",
       "      <td>(0.654, 0.602)</td>\n",
       "      <td>(0.640, 0.6)</td>\n",
       "      <td>(0.659, 0.5)</td>\n",
       "      <td>(0.618, 0.722)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QCOM</td>\n",
       "      <td>(0.586, 0.568)</td>\n",
       "      <td>(0.561, 0.591)</td>\n",
       "      <td>(0.546, 0.637)</td>\n",
       "      <td>(0.596, 0.478)</td>\n",
       "      <td>(0.593, 0.391)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>(0.642, 0.571)</td>\n",
       "      <td>(0.705, 0.454)</td>\n",
       "      <td>(0.65, 0.5)</td>\n",
       "      <td>(0.652, 0.4)</td>\n",
       "      <td>(0.615, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>(0.655, 0.494)</td>\n",
       "      <td>(0.619, 0.461)</td>\n",
       "      <td>(0.647, 0.5)</td>\n",
       "      <td>(0.555, 0.38)</td>\n",
       "      <td>(0.638, 0.573)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>(0.580, 0.476)</td>\n",
       "      <td>(0.674, 0.530)</td>\n",
       "      <td>(0.679, 0.532)</td>\n",
       "      <td>(0.651, 0.570)</td>\n",
       "      <td>(0.655, 0.566)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Stock Name 0.5 Training Ratio 0.6 Training Ratio 0.7 Training Ratio  \\\n",
       "0      GOOGL     (0.737, 0.551)     (0.545, 0.458)     (0.680, 0.474)   \n",
       "1       INTC     (0.534, 0.468)     (0.544, 0.437)      (0.68, 0.510)   \n",
       "2       AAPL       (0.6, 0.501)     (0.588, 0.499)     (0.594, 0.484)   \n",
       "3       CSCO     (0.663, 0.604)     (0.654, 0.602)       (0.640, 0.6)   \n",
       "4       QCOM     (0.586, 0.568)     (0.561, 0.591)     (0.546, 0.637)   \n",
       "5       NVDA     (0.642, 0.571)     (0.705, 0.454)        (0.65, 0.5)   \n",
       "6       AMZN     (0.655, 0.494)     (0.619, 0.461)       (0.647, 0.5)   \n",
       "7       MSFT     (0.580, 0.476)     (0.674, 0.530)     (0.679, 0.532)   \n",
       "\n",
       "  0.8 Training Ratio 0.9 Training Ratio  \n",
       "0     (0.636, 0.467)     (0.631, 0.394)  \n",
       "1     (0.587, 0.437)     (0.633, 0.437)  \n",
       "2     (0.589, 0.456)     (0.582, 0.461)  \n",
       "3       (0.659, 0.5)     (0.618, 0.722)  \n",
       "4     (0.596, 0.478)     (0.593, 0.391)  \n",
       "5       (0.652, 0.4)       (0.615, 0.5)  \n",
       "6      (0.555, 0.38)     (0.638, 0.573)  \n",
       "7     (0.651, 0.570)     (0.655, 0.566)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(stk_lst)\n",
    "df[[\"Stock Name\"] + training_ratio_names  ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
